{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cscaudill/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/cscaudill/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train_users_2.csv')\n",
    "df_test = pd.read_csv('./test_users.csv')\n",
    "labels = df_train['country_destination'].values\n",
    "id_test = df_test['id']\n",
    "df_train = df_train.drop(['country_destination'], axis=1)\n",
    "piv_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate the train and test user files\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "# drop columns unecessary for prediction\n",
    "df_all = df_all.drop(['id', 'date_first_booking'], axis=1)\n",
    "\n",
    "#fill NA values with -1\n",
    "df_all = df_all.fillna(-1)\n",
    "\n",
    "# replace '/' with '-' in date fields for consistency\n",
    "for i in range(len(df_all.date_account_created.values)):\n",
    "        df_all.date_account_created.values[i] = df_all.date_account_created.values[i].replace('/','-')\n",
    "\n",
    "# split date fields into 3 columns (year, month, day) to avoid having a feature for every possible date\n",
    "dac = np.vstack(df_all.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "df_all['dac_year'] = dac[:,0]\n",
    "df_all['dac_month'] = dac[:,1]\n",
    "df_all['dac_day'] = dac[:,2]\n",
    "df_all = df_all.drop(['date_account_created'], axis=1)\n",
    "\n",
    "# encode categorical features with dummy values\n",
    "ohe_feats = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for f in ohe_feats:\n",
    "    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n",
    "    df_all = df_all.drop([f], axis=1)\n",
    "    df_all = pd.concat((df_all, df_all_dummy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After cleansing, split the data back up between the train and test users\n",
    "vals = df_all.values\n",
    "train_vals = vals[:piv_train]\n",
    "test_vals = vals[piv_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split training values between train & dev sets \n",
    "\n",
    "np.random.seed(0)\n",
    "msk = np.random.rand(len(train_vals)) < 0.75\n",
    "train = train_vals[msk]\n",
    "train_labs = labels[msk]\n",
    "dev = train_vals[~msk]\n",
    "dev_labs = labels[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Regularization Strength: {'C': 0.0001}\n",
      "LogReg F1: 0.584372789217\n"
     ]
    }
   ],
   "source": [
    "strengths = {'C': [0.0001,0.001,0.01,0.1,0.3,0.5,1.0]}\n",
    "clf_lr = GridSearchCV(LogisticRegression(), strengths, scoring='f1_micro')\n",
    "clf_lr.fit(train, train_labs)\n",
    "preds = clf_lr.predict(dev)\n",
    "print \"Optimal Regularization Strength:\", clf_lr.best_params_\n",
    "print \"LogReg F1:\", metrics.f1_score(dev_labs, preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Kaggle Submission\n",
    "\n",
    "sub = pd.DataFrame(np.column_stack((id_test, preds)), columns=['id', 'country'])\n",
    "sub.to_csv('sub.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
