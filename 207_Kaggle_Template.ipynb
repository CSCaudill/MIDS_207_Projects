{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train_users_2.csv')\n",
    "df_test = pd.read_csv('./test_users.csv')\n",
    "# sessions = pd.read_csv('./sessions.csv')\n",
    "id_test = df_test['id']\n",
    "#df_train = df_train[df_train.country_destination.str.contains(\"NDF\") == False]\n",
    "labels = df_train['country_destination'].values\n",
    "df_train = df_train.drop(['country_destination'], axis=1)\n",
    "piv_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split date fields into 3 columns (year, month, day) to avoid having a feature for every possible date\n",
    "dac = np.vstack(df_train.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('/')))).values)\n",
    "df_train['acct_create_month'] = dac[:,0]\n",
    "df_train['acct_create_day'] = dac[:,1]\n",
    "df_train['acct_create_year'] = dac[:,2]\n",
    "\n",
    "# train and test data use different formats, so this is doing the same thing as above\n",
    "dac = np.vstack(df_test.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "df_test['acct_create_month'] = dac[:,1]\n",
    "df_test['acct_create_day'] = dac[:,2]\n",
    "df_test['acct_create_year'] = dac[:,0]\n",
    "\n",
    "# concatenate the train and test user files\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "# concat account create month/year\n",
    "df_all['acct_create_month_year'] = df_all.acct_create_month.astype(str) +'/'+ df_all.acct_create_year.astype(str)\n",
    "\n",
    "# drop columns unecessary for prediction\n",
    "df_all = df_all.drop(['id', 'date_first_booking','date_account_created','timestamp_first_active','acct_create_day','acct_create_month','acct_create_year'], axis=1)\n",
    "\n",
    "#set unknown gender values to NA\n",
    "df_all.gender = df_all.gender.replace('-unknown-',np.nan)\n",
    "\n",
    "#fill NA values with -1\n",
    "df_all = df_all.fillna(-1)\n",
    "\n",
    "# The age field is populated with some outlying values and some year values (e.g., 2014)\n",
    "# This will pull only ages between 14 and 100\n",
    "av = df_all.age.values\n",
    "df_all['age'] = np.where(np.logical_or(av<14, av>100), -1, av)\n",
    "\n",
    "# encode categorical features with dummy values\n",
    "categorical = ['acct_create_month_year', 'age', 'gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for f in categorical:\n",
    "    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n",
    "    df_all = df_all.drop([f], axis=1)\n",
    "    df_all = pd.concat((df_all, df_all_dummy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After cleansing, split the data back up between the train and test users\n",
    "vals = df_all.values\n",
    "train_vals = vals[:piv_train]\n",
    "test_vals = vals[piv_train:]\n",
    "\n",
    "# Split training values between train & dev sets \n",
    "\n",
    "np.random.seed(0)\n",
    "msk = np.random.rand(len(train_vals)) < 0.75\n",
    "\n",
    "train_data = train_vals[msk]\n",
    "train_labs = labels[msk]\n",
    "\n",
    "dev_data = train_vals[~msk]\n",
    "dev_labs = labels[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Model Begins Here:\n",
    "\n",
    "## Be sure to keep the test predictions in the variable named \"test_preds\". This will allow the subsequent cells to pull out the top 5 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Regularization Strength: {'C': 0.001}\n",
      "LogReg F1: 0.623654913058\n"
     ]
    }
   ],
   "source": [
    "strengths = {'C': [0.0001,0.001,0.01,0.1,0.3,0.5,1.0]}\n",
    "\n",
    "# GridSearch for optimal regularization strength\n",
    "clf_lr = GridSearchCV(LogisticRegression(), strengths, scoring='f1_micro')\n",
    "clf_lr.fit(train_data, train_labs)\n",
    "\n",
    "# development predictions\n",
    "dev_preds = clf_lr.predict(dev_data)\n",
    "\n",
    "# predictions on test data\n",
    "test_preds = clf_lr.predict_proba(test_vals)\n",
    "\n",
    "print \"Optimal Regularization Strength:\", clf_lr.best_params_\n",
    "print \"LogReg F1:\", metrics.f1_score(dev_labs, dev_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(train_labs)\n",
    "#Taking the 5 classes with highest probabilities\n",
    "user_ids = []  #list of ids\n",
    "countries = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    user_ids += [idx] * 5\n",
    "    countries += le.inverse_transform(np.argsort(test_preds[i])[::-1])[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Kaggle Submission\n",
    "\n",
    "sub = pd.DataFrame(np.column_stack((user_ids, countries)), columns=['id', 'country'])\n",
    "sub.to_csv('sub_MODELNAME.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
